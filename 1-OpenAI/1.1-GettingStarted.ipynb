{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "293f119e",
   "metadata": {},
   "source": [
    "#### Getting started with LangChain and OpenAI\n",
    "This guide will walk you through the steps to get started with LangChain and OpenAI. We'll cover below things:\n",
    "\n",
    "- Build simple application with Langchain\n",
    "- Components of LangChain: prompt templates, models and output parsers\n",
    "- Trace application with Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "12124fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # take environment variables from .env.file\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "04c89ae6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LangSmithTracer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Setup tracer\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m tracer = \u001b[43mLangSmithTracer\u001b[49m(project_name=project_name)\n",
      "\u001b[31mNameError\u001b[39m: name 'LangSmithTracer' is not defined"
     ]
    }
   ],
   "source": [
    "# Setup tracer\n",
    "tracer = LangSmithTracer(project_name=project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69f4f364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x00000186385B9550> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000186374731D0> root_client=<openai.OpenAI object at 0x00000186385E9130> root_async_client=<openai.AsyncOpenAI object at 0x000001863747B350> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********') stream_usage=True\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7680bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#invoke LLM by passing the input\n",
    "response = llm.invoke(\"What is LangChain?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a110768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"LangChain is a framework designed for developing applications powered by large language models (LLMs). It provides a robust toolkit to facilitate the integration of LLMs with various data sources, enabling developers to build complex applications that can perform a wide range of tasks, such as natural language understanding, automated reasoning, and interactive querying.\\n\\nKey Features of LangChain:\\n1. **Modular Components**: LangChain is built on a modular architecture, allowing developers to customize and extend its functionality to suit specific application needs.\\n\\n2. **Integration with External Data Sources**: LangChain supports integration with external data sources like databases, APIs, and file systems, enabling LLMs to work with real-world data seamlessly.\\n\\n3. **Agent Systems**: The framework facilitates the creation of agent systems where language models can act autonomously or semi-autonomously, making decisions based on the data and context they're presented with.\\n\\n4. **Chain of Thought**: LangChain supports the development of complex, multi-step reasoning processes by enabling chains of logic and operations applied to inputs and outputs.\\n\\n5. **Ease of Use**: It offers a user-friendly interface with abstractions that simplify the complexity of handling large language models and integrating them within larger applications.\\n\\nLangChain is typically used in natural language processing applications but can be adapted to any domain where LLMs can provide value, such as conversational AI, decision support systems, content generation, and more.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 286, 'prompt_tokens': 12, 'total_tokens': 298, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CQq6cnV78ZpE2kZ8peOY1yLJYtQHz', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--cc416cc9-05ef-4829-81c7-d6b57a2e0a82-0' usage_metadata={'input_tokens': 12, 'output_tokens': 286, 'total_tokens': 298, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70c174b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create chain prompt template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [   (\"system\", \"You are an expert AI Engineer who explains technical concepts clearly.\"),\n",
    "        (\"user\", \"Question: {input}\")\n",
    "   ]\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d5f640c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chain \n",
    "\n",
    "chain = prompt | llm\n",
    "response = chain.invoke({\"input\": \"What is LangChain?\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b3a14bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='LangChain is a framework designed to facilitate the development and deployment of applications that utilize large language models (LLMs). It provides the tools and infrastructure necessary for building advanced applications that leverage the power of these models to handle complex language tasks.\\n\\nKey features of LangChain include:\\n\\n1. **Chain Creation**: LangChain allows developers to create chains, which are sequences of calls to language models or other utilities linked together to accomplish specific tasks. These chains help in structuring multi-step workflows where the output of one language model can be used as the input to another.\\n\\n2. **Memory Management**: The framework includes mechanisms to manage \"memory\" within chains, permitting applications to maintain context between interactions. This is crucial for creating conversational agents that can remember past interactions and use them in future exchanges.\\n\\n3. **Integration with External Data Sources**: LangChain can connect with external data sources, such as search engines, databases, and APIs. This enables applications to fetch and process additional information, enhancing their functionality and accuracy.\\n\\n4. **Prompt Management**: LangChain provides tools for prompt management, allowing developers to define and handle prompts for LLMs efficiently. This can involve templating, versioning, and managing dynamic inputs to prompts, making the interaction with LLMs more robust and flexible.\\n\\n5. **Deployment Capabilities**: The framework supports deployment in various environments, making it easier for developers to transition from development to production. It offers options for scaling and optimizing performance when integrating LLMs within applications.\\n\\nOverall, LangChain is a versatile tool for creators looking to harness the capabilities of large language models in innovative and practical ways, streamlining the development process of AI-driven applications.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 338, 'prompt_tokens': 30, 'total_tokens': 368, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CQqcBLVb5c5Z6UlEKK1OgF4FQ5Riz', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--32266da3-2e5b-4cf2-907f-842fd891e990-0' usage_metadata={'input_tokens': 30, 'output_tokens': 338, 'total_tokens': 368, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "707d503f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cbee2795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a framework designed to facilitate the development of applications that utilize language models, such as OpenAI's GPT, for various tasks. It's particularly focused on enhancing these applications by providing tools to manage and integrate different data sources, construct pipelines for complex interactions, and optimize the language model's functionality in diverse and dynamic environments.\n",
      "\n",
      "The core idea behind LangChain is to leverage the power of language models beyond straightforward text generation and into more structured and dynamic workflows. Here are some key components and features of LangChain:\n",
      "\n",
      "1. **Chains**: LangChain enables developers to build sequences of calls to a language model. These chains can handle different inputs, process them with logic, and return complex outputs. This allows for creating more sophisticated applications that require multiple steps or conditional logic.\n",
      "\n",
      "2. **Data Connectors**: The framework offers connectors to various data stores, enabling language models to fetch data or document knowledge bases, which makes them more contextually aware and capable of providing accurate and relevant outputs.\n",
      "\n",
      "3. **Memory Management**: LangChain includes memory components that help in tracking and managing state across interactions. This is particularly useful in applications where context needs to be maintained across user sessions or conversations.\n",
      "\n",
      "4. **Framework Flexibility**: It's framework-agnostic, meaning it can be adapted to various existing tech stacks, offering a high degree of integration flexibility whether you are building something with Python, JavaScript, or other technologies.\n",
      "\n",
      "5. **Tools and Utilities**: LangChain provides a suite of tools and utilities designed to streamline the process of integrating language models into applications, including error handling, data transformation, and infrastructure management.\n",
      "\n",
      "LangChain is particularly useful for developers working on conversational AI, virtual assistants, customer support systems, and other applications where language understanding and generation play a critical role. By providing a structured framework, LangChain helps streamline the development process and enhances the capabilities of language model-based solutions.\n"
     ]
    }
   ],
   "source": [
    "#stroutput parser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser = StrOutputParser() \n",
    "\n",
    "chain = prompt | llm | parser\n",
    "response = chain.invoke({\"input\": \"What is LangChain?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436d7d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_langchain (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
