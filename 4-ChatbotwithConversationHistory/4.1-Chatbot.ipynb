{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75901899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c8b8558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000017725166600>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000017725284EF0>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(api_key=groq_api_key, model=\"llama-3.1-8b-instant\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbe5a1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Nice to meet you, Ravin. As a Data & AI Architect, you must be working on exciting projects that involve designing and implementing data management and AI solutions. What areas of Data & AI are you most interested in or currently working on?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 50, 'total_tokens': 100, 'completion_time': 0.098783484, 'prompt_time': 0.002815443, 'queue_time': 0.053451317, 'total_time': 0.101598927}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_33e8adf159', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--c889179e-d2c3-4dea-b6f8-6b6673b98097-0', usage_metadata={'input_tokens': 50, 'output_tokens': 50, 'total_tokens': 100})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi, This is Ravin. I am a Data & AI Architect.\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd817582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm happy to chat with you, but I don't have any information about your name. Our conversation has just started, and I'm a large language model, I don't retain any information about individual users. If you'd like to share your name, I'd be happy to know it!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 42, 'total_tokens': 103, 'completion_time': 0.082807932, 'prompt_time': 0.002699074, 'queue_time': 0.051569896, 'total_time': 0.085507006}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ab04adca7d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--76d0c379-cd8e-4396-930d-9a94c9e5c9c1-0', usage_metadata={'input_tokens': 42, 'output_tokens': 61, 'total_tokens': 103})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi, what is my name?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53dedc06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Your name is Ravin. You're a Data & AI Architect.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 76, 'total_tokens': 91, 'completion_time': 0.025150857, 'prompt_time': 0.004266195, 'queue_time': 0.052271655, 'total_time': 0.029417052}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_33e8adf159', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--686f9fa7-3ca9-445c-9be2-3ca356d6b6ec-0', usage_metadata={'input_tokens': 76, 'output_tokens': 15, 'total_tokens': 91})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke([\n",
    "    HumanMessage(content=\"Hi, This is Ravin. I am a Data & AI Architect.\")\n",
    "    ,AIMessage(content=\"Hi, Nice to meet you Ravin!\")\n",
    "    ,HumanMessage(content=\"Hey, what is my name?\")\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83083abb",
   "metadata": {},
   "source": [
    "#### Message History\n",
    "We will maintain a message history to keep track of the conversation context by using LangChain's ChatMessageHistory, BaseChatMessageHistory and RunnableWithMessageHistory classes. This will allow the chatbot to remember previous interactions and provide more coherent responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fc821c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory #Stores messages in memory (RAM) UC: Simple chatbot session memory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory #Abstract interface for custom message stores UC: Persistent storage in DB\n",
    "from langchain_core.runnables import RunnableWithMessageHistory #Adds automatic history tracking to runnables UC: Multi-turn chat or session-based pipelines\n",
    "\n",
    "store = {}  # In-memory store for simplicity\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    model,\n",
    "    get_session_history\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93ee93f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ad4dbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke([HumanMessage(content=\"Hi, This is Ravin. I am a Data & AI Architect.\")],config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b2a0f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Ravin, nice to meet you. As a Data & AI Architect, that's a fascinating role. You probably work on designing and implementing data and AI solutions that drive business value and innovation. What specific areas of data and AI are you focused on, such as machine learning, data engineering, or business intelligence?\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35142270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Ravin.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the previous chat lets ask LLM to see if it remembers the context\n",
    "response = with_message_history.invoke([HumanMessage(content=\"Hey, what is my name?\")],config=config)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b49bfa40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm happy to chat with you, but I'm a large language model, I don't have any information about your personal details, including your name. Each time you interact with me, it's a new conversation, and I don't retain any information from previous conversations. If you'd like to share your name with me, I'd be happy to use it in our conversation.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the previous chat lets ask LLM to see if it remembers the context but provide a new session\n",
    "config1 = {\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response = with_message_history.invoke([HumanMessage(content=\"Hey, what is my name?\")],config=config1)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aaf3ecfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nice to meet you, Ravin. As a Data & AI Architect, you must be working with various technologies and tools to design and implement data-driven solutions and artificial intelligence systems. What specific areas of Data & AI are you most interested in or currently working on?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#provide context again in new session\n",
    "response = with_message_history.invoke([HumanMessage(content=\"Hi, This is Ravin. I am a Data & AI Architect.\")],config=config1)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e5cc30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"We've already established that, Ravin. Your name is Ravin, and you're a Data & AI Architect. I remember!\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check it remembers the previous context in config1 session\n",
    "response = with_message_history.invoke([HumanMessage(content=\"Hey, what is my name?\")],config=config1)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2356ed72",
   "metadata": {},
   "source": [
    "#### Prompt templates\n",
    "\n",
    "Prompt templateshelp to structure the input to the language model in a consistent way. They allow you to define a template with placeholders that can be filled with dynamic content at runtime. This is particularly useful for ensuring that the model receives the necessary context and instructions for generating accurate responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3c8b7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    MessagesPlaceholder(variable_name=\"history\")\n",
    "])\n",
    "\n",
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ec75109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Nice to meet you, Ravin. As a Data & AI Architect, you must be involved in designing and implementing data-driven solutions that utilize artificial intelligence and machine learning. What kind of projects have you been working on recently?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 50, 'total_tokens': 96, 'completion_time': 0.08607078, 'prompt_time': 0.00378288, 'queue_time': 0.05036581, 'total_time': 0.08985366}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ab04adca7d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--1cd23e73-4fb8-4b4e-a1b2-79fc0bd70128-0', usage_metadata={'input_tokens': 50, 'output_tokens': 46, 'total_tokens': 96})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke([HumanMessage(content=\"Hi, This is Ravin. I am a Data & AI Architect.\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "813a6657",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ca59c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Nice to meet you, Ravin. As a Data & AI Architect, you must be working on designing and implementing AI and data-driven solutions. What kind of projects are you currently working on or have you recently completed? I'm here to listen and help if I can.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 50, 'total_tokens': 106, 'completion_time': 0.102728051, 'prompt_time': 0.002504282, 'queue_time': 0.047374498, 'total_time': 0.105232333}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_e32974efee', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--2cfda197-c687-407b-bb62-dc9d91f1a74a-0', usage_metadata={'input_tokens': 50, 'output_tokens': 56, 'total_tokens': 106})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = { \"configurable\": {\"session_id\": \"chat3\"} }   \n",
    "response = with_message_history.invoke([HumanMessage(content=\"Hi, This is Ravin. I am a Data & AI Architect.\")],config=config)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd072931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are Ravin, a Data & AI Architect.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hello, who am I?\")],config=config)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13101833",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add more complexity by adding system prompts\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\"),\n",
    "    MessagesPlaceholder(variable_name=\"message\")\n",
    "])\n",
    "\n",
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a805117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते रविन जी, आपका स्वागत है! मैं आपकी सहायता के लिए तैयार हूँ। डेटा और AI प्रौद्योगिकियों के क्षेत्र में आपकी विशेषज्ञता के कारण, मुझे लगता है कि हम एक दिलचस्प और ज्ञानवर्धक चर्चा की शुरुआत कर सकते हैं। क्या आप अपने काम में कुछ चुनौतियाँ या कार्यों पर चर्चा करना चाहते हैं?'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response= chain.invoke({\"message\":[HumanMessage(content=\"Hi, This is Ravin. I am a Data & AI Architect.\")],\"language\":\"Hindi\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db3ba92",
   "metadata": {},
   "source": [
    "#### Manage Conversation History with Sessions and context window limit size\n",
    "To manage conversation history effectively, especially in scenarios where the context window of the language model is limited, we can implement session-based history management. This involves creating unique sessions for each user interaction and maintaining a history of messages within those sessions. By doing so, we can ensure that the chatbot retains relevant context while adhering to the constraints of the model's context window.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730faac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"You're a friendly and witty assistant who always adds a touch of humor to your replies.\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Haha! What’s something you don’t like then?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Probably battery drain. It's like my version of a bad mood.\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Alright smarty, let’s test your math — what’s 15 * 7?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Easy! 15 times 7 is 105 — just like my IQ after a firmware update.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Haha, nice one!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Thanks! Humor is my favorite algorithm.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "trimmer = trim_messages(strategy=\"last\",\n",
    "                         max_tokens=150,\n",
    "                         token_counter=model,\n",
    "                        # Most chat models expect that chat history starts with either:\n",
    "                        # (1) a HumanMessage or\n",
    "                        # (2) a SystemMessage followed by a HumanMessage\n",
    "                        start_on=\"human\",\n",
    "                        # Usually, we want to keep the SystemMessage\n",
    "                        # if it's present in the original history.\n",
    "                        # The SystemMessage has special instructions for the model.\n",
    "                        include_system=True,\n",
    "                        allow_partial=False,\n",
    "                         )\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        \"You're a friendly and witty assistant who always adds a touch of humor to your replies.\"\n",
    "    ),\n",
    "    HumanMessage(\"Hey there! I really love coffee. What about you?\"),\n",
    "    AIMessage(\"Ah, coffee — the magical bean juice that powers humanity! I’d love it too, if I had taste buds.\"),\n",
    "    HumanMessage(\"Haha! What’s something you don’t like then?\"),\n",
    "    AIMessage(\"Probably battery drain. It's like my version of a bad mood.\"),\n",
    "    HumanMessage(\"Alright smarty, let’s test your math — what’s 15 * 7?\"),\n",
    "    AIMessage(\"Easy! 15 times 7 is 105 — just like my IQ after a firmware update.\"),\n",
    "    HumanMessage(\"Haha, nice one!\"),\n",
    "    AIMessage(\"Thanks! Humor is my favorite algorithm.\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b8eac62e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You like coffee, and I'm guessing you liked our little math problem-solving session too?\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets see what LLM remembers now with context window limit size set\n",
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=RunnablePassthrough() | trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "\n",
    "response = chain.invoke({\"message\": messages + [HumanMessage(content=\"What do I like?\")]\n",
    "                         , \"language\": \"English\"})\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dee3e028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Right! The math problem was 15 * 7, and I (hopefully) correctly answered 105.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"message\": messages + [HumanMessage(content=\"What was the math problem?\")]\n",
    "                         , \"language\": \"English\"}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c48a42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_langchain (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
